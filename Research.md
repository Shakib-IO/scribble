#### **Research Blog**
- [Reproduce Super Resolution](https://towardsdatascience.com/learn-to-reproduce-papers-beginners-guide-2b4bff8fcca0)
- [Reproduce GAN](https://towardsdatascience.com/converting-deep-learning-research-papers-to-code-f-f38bbd87352f)
- [Debugging Deep Learning Docker Containers](https://python.plainenglish.io/debugging-deep-learning-docker-containers-3815a44c9519)
- [Docker for Reproducible Research](https://tilburgsciencehub.com/building-blocks/automate-and-execute-your-work/reproducible-work/docker/)
- [Docker for Reproducible Research with W&B](https://wandb.ai/site/articles/towards-reproducibility)
- [Docker for Reproducible Research with W&B on medium](https://medium.com/@stephanie_88121/we-made-docker-easy-to-use-for-reproducibility-in-machine-learning-experiments-521c0eef94f6)
- [Dataset Portal](https://datasetninja.com/)

#### **Tools**
- [labml.ai](https://nn.labml.ai/index.html)



#### Notes

- Multi-Layer Perceptrons (MLPs) prevent Vision Transformers (ViTs) from producing a rank-1 matrix because MLPs introduce non-linearity through activation functions in their layers. This non-linearity disrupts the ability to represent the data as a simple outer product of two vectors, which is characteristic of a rank-1 matrix. In contrast, ViTs rely on self-attention mechanisms that do not introduce non-linearities in the same way as MLPs, allowing them to potentially produce rank-1 matrices. [AdaptFormer](https://arxiv.org/pdf/2205.13535.pdf)
